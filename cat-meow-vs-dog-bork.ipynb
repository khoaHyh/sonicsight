{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4712,"sourceType":"datasetVersion","datasetId":2749}],"dockerImageVersionId":30185,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Saving a Cats Meow v Dogs Bork Model","metadata":{"_uuid":"2234355c-10f0-427f-817d-6f0e0f98f43f","_cell_guid":"d162daf9-d060-40c2-8936-749cf1e8e543","trusted":true,"collapsed":false,"id":"98d53c05","jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"This is a minimal example showing how to train a fastai model on Kaggle, and save it so you can use it in your app.","metadata":{"_uuid":"5f0c193d-2366-47d4-a007-d27cc8321066","_cell_guid":"91f896fc-9f45-44a3-bb06-ffd7c0f0a371","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Make sure we've got the latest version of fastai:\n!pip install -Uqq fastai nbdev","metadata":{"_uuid":"1a09ade0-a24c-4e76-9937-a4a78c680673","_cell_guid":"486f66cb-a0bb-452c-b6fe-608927450301","trusted":true,"collapsed":false,"id":"evvA0fqvSblq","outputId":"ba21b811-767c-459a-ccdf-044758720a55","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-03-19T00:18:53.801511Z","iopub.execute_input":"2025-03-19T00:18:53.801737Z","iopub.status.idle":"2025-03-19T00:19:02.119159Z","shell.execute_reply.started":"2025-03-19T00:18:53.801680Z","shell.execute_reply":"2025-03-19T00:19:02.118219Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastai.vision.all import *\nimport librosa\nimport librosa.display\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport os\nimport pandas as pd\nimport shutil","metadata":{"_uuid":"164846a0-f302-4db0-851a-6a6886f57d89","_cell_guid":"8e650de5-d7ab-4785-aa83-2f464a7b831f","trusted":true,"collapsed":false,"id":"44eb0ad3","execution":{"iopub.status.busy":"2025-03-19T00:19:02.122796Z","iopub.execute_input":"2025-03-19T00:19:02.123008Z","iopub.status.idle":"2025-03-19T00:19:03.484362Z","shell.execute_reply.started":"2025-03-19T00:19:02.122981Z","shell.execute_reply":"2025-03-19T00:19:03.483400Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Download ESC-50 dataset and set up the directories:","metadata":{"_uuid":"6b5eb25d-7c4c-4442-8ec7-debdf5cf4bdf","_cell_guid":"f1c4a58e-e45d-4fb2-a73a-037042c51156","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Remove old zips\n!rm -rf /kaggle/working/*.zip*\n\n# Download ESC-50 dataset\n!wget -q https://github.com/karoldvl/ESC-50/archive/master.zip\n!unzip -q -o master.zip\n\n# Load metadata\nmeta_df = pd.read_csv('ESC-50-master/meta/esc50.csv')\n\n# Create directories\ncat_folder = Path('animal_sounds/cat')\ndog_folder = Path('animal_sounds/dog')\ncat_folder.mkdir(parents=True, exist_ok=True)\ndog_folder.mkdir(parents=True, exist_ok=True)\n\n# Extract cat and dog files\ncat_files = meta_df[meta_df['category'] == 'cat']\ndog_files = meta_df[meta_df['category'] == 'dog']\n\n# Copy files to respective folders\nfor _, row in cat_files.iterrows():\n    src = f\"ESC-50-master/audio/{row['filename']}\"\n    dst = f\"animal_sounds/cat/{row['filename']}\"\n    shutil.copy(src, dst)\n    \nfor _, row in dog_files.iterrows():\n    src = f\"ESC-50-master/audio/{row['filename']}\"\n    dst = f\"animal_sounds/dog/{row['filename']}\"\n    shutil.copy(src, dst)\n\nprint(f\"Copied {len(cat_files)} cat sounds and {len(dog_files)} dog sounds\")\n\n# Now use 'animal_sounds' as your audio_folder\naudio_folder = 'animal_sounds'","metadata":{"_uuid":"bff9616f-6889-4b98-8b54-96796aa40da4","_cell_guid":"5000e3a8-35a7-4144-a8e0-45ac700c7cbb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:19:03.485670Z","iopub.execute_input":"2025-03-19T00:19:03.485920Z","iopub.status.idle":"2025-03-19T00:19:55.416031Z","shell.execute_reply.started":"2025-03-19T00:19:03.485891Z","shell.execute_reply":"2025-03-19T00:19:55.415088Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Download a separate cat and dog dataset","metadata":{}},{"cell_type":"code","source":"# Install Kaggle API package\n!pip install -q kaggle\n\n# Path to the dataset in the input section\ndataset_path = Path(\"/kaggle/input/audio-cats-and-dogs\")\n\n# Get all cat files from both test and train directories\ncat_files = list(dataset_path.glob(\"cats_dogs/test/cats/*\")) + list(dataset_path.glob(\"cats_dogs/train/cat/*\"))\n\n# Get all dog files from both test and train directories  \ndog_files = list(dataset_path.glob(\"cats_dogs/test/dogs/*\")) + list(dataset_path.glob(\"cats_dogs/train/dog/*\"))\n\n# Copy files to respective folders\nfor filepath in cat_files:\n    src = filepath\n    filename = Path(filepath).name\n    dst = f\"animal_sounds/cat/{filename}\"\n    shutil.copy(src, dst)\n    \nfor filepath in dog_files:\n    src = filepath\n    filename = Path(filepath).name\n    dst = f\"animal_sounds/dog/{filename}\"\n    shutil.copy(src, dst)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-19T00:19:55.417253Z","iopub.execute_input":"2025-03-19T00:19:55.417453Z","iopub.status.idle":"2025-03-19T00:20:03.617649Z","shell.execute_reply.started":"2025-03-19T00:19:55.417428Z","shell.execute_reply":"2025-03-19T00:20:03.616824Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create a helper function to generate spectrograms:","metadata":{"_uuid":"3d86f6f7-fc91-48a2-a2c6-7d0ce5d36a3e","_cell_guid":"846b1442-37f9-423c-b094-bad5ab676768","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def create_spectrogram(audio_path, save_path=None):\n    y, sr = librosa.load(audio_path)\n    # create mel-spectrogram\n    mel_spec = librosa.feature.melspectrogram(\n        y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128\n    )\n    # convert to log scale (dB)\n    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n\n    # plot and save as image\n    plt.figure(figsize=(8,6))\n    librosa.display.specshow(log_mel_spec, sr=sr, x_axis='time', y_axis='mel')\n    plt.tight_layout()\n    plt.axis('off')\n\n    if save_path:\n        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n        plt.close()\n        return save_path\n    else:\n        plt.close()\n        return log_mel_spec","metadata":{"_uuid":"ccce095b-2e96-4c5d-8189-1a183b1ce498","_cell_guid":"10bd1dc4-ea86-4946-ac3e-568c4b509184","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:20:03.619646Z","iopub.execute_input":"2025-03-19T00:20:03.619885Z","iopub.status.idle":"2025-03-19T00:20:03.625636Z","shell.execute_reply.started":"2025-03-19T00:20:03.619858Z","shell.execute_reply":"2025-03-19T00:20:03.624983Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set up folders\nspec_folder = './spectrograms'\nPath(spec_folder).mkdir(exist_ok=True, parents=True)\n\n# Process audio files to spectrograms\nfor label in ['cat', 'dog']:\n    (Path(spec_folder)/label).mkdir(exist_ok=True)\n\n    audio_path = Path(f\"{audio_folder}/{label}\")\n    if audio_path.exists():\n        files = list(audio_path.glob(\"*.wav\"))\n        print(f\"Processing {len(files)} {label} audio files...\")\n\n        for i, file in enumerate(files):\n            output_file = Path(spec_folder)/label/f\"{file.stem}.png\"\n            create_spectrogram(str(file), str(output_file))\n            if i % 10 == 0:\n                print(f\"Processed {i}/{len(files)} files\")\n\nprint(f\"Total spectrograms created: {len(list(Path(spec_folder).glob('**/*.png')))}\")","metadata":{"_uuid":"cbea7004-fc09-41df-b5d1-0f017eb7f127","_cell_guid":"83f81f80-5f6a-4161-9ba2-5ec5f8a23b49","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:20:03.626799Z","iopub.execute_input":"2025-03-19T00:20:03.627328Z","iopub.status.idle":"2025-03-19T00:22:04.154541Z","shell.execute_reply.started":"2025-03-19T00:20:03.627291Z","shell.execute_reply":"2025-03-19T00:22:04.153795Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_cat = list(Path(f\"{spec_folder}/cat\").glob(\"*.png\"))[0]\nsample_dog = list(Path(f\"{spec_folder}/dog\").glob(\"*.png\"))[0]","metadata":{"_uuid":"10cab068-7bb5-48bc-b838-6300f503825d","_cell_guid":"907bf7af-5ff8-4ec4-b11d-6b625db35f97","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:22:04.155712Z","iopub.execute_input":"2025-03-19T00:22:04.155998Z","iopub.status.idle":"2025-03-19T00:22:04.161723Z","shell.execute_reply.started":"2025-03-19T00:22:04.155963Z","shell.execute_reply":"2025-03-19T00:22:04.161057Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image.open(sample_cat)","metadata":{"_uuid":"686a6c64-49d9-430a-906a-8744340c339a","_cell_guid":"e0308aea-70e9-46b0-82b2-ddfa6e967d33","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:22:04.162604Z","iopub.execute_input":"2025-03-19T00:22:04.162836Z","iopub.status.idle":"2025-03-19T00:22:04.203390Z","shell.execute_reply.started":"2025-03-19T00:22:04.162811Z","shell.execute_reply":"2025-03-19T00:22:04.202810Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Image.open(sample_dog)","metadata":{"_uuid":"b93edfd7-98bf-4d0b-b9ec-d43801eb3100","_cell_guid":"4120fb29-aa60-44f1-9b13-7b72d381d0d9","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:22:04.204177Z","iopub.execute_input":"2025-03-19T00:22:04.204325Z","iopub.status.idle":"2025-03-19T00:22:04.225332Z","shell.execute_reply.started":"2025-03-19T00:22:04.204306Z","shell.execute_reply":"2025-03-19T00:22:04.224632Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Note:** Unpacking the `aug_transforms()` function was helpful to control specific parameters rather than using the defaults. Playing with the spectrograms rotation, zoom, lighting, and warping helped with lowering error rate and getting a better loss.\nNow we can create our `DataLoaders`:","metadata":{"_uuid":"1cc47720-ee57-4085-acf2-075441371128","_cell_guid":"be46982d-8086-43ab-8e78-b7c35e3f286b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Create DataBlock and train model\ndblock = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(),\n    get_y=parent_label,\n    item_tfms=Resize(224),\n    batch_tfms = [\n        *aug_transforms(max_rotate=10, max_zoom=1.1, max_lighting=0.2, max_warp=0),\n        Normalize.from_stats(*imagenet_stats)\n    ]\n)\n\ndls = dblock.dataloaders(spec_folder, bs=16)\ndls.show_batch()","metadata":{"_uuid":"bc7e9707-c041-455f-838e-1c0d1f400774","_cell_guid":"13b0eed5-4d5c-4cff-8579-221dad25dbee","trusted":true,"collapsed":false,"id":"44eb0ad3","execution":{"iopub.status.busy":"2025-03-19T00:22:04.226288Z","iopub.execute_input":"2025-03-19T00:22:04.226537Z","iopub.status.idle":"2025-03-19T00:22:07.164630Z","shell.execute_reply.started":"2025-03-19T00:22:04.226506Z","shell.execute_reply":"2025-03-19T00:22:07.163978Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"... and train our model, a resnet50:","metadata":{"_uuid":"f981943b-a369-4a07-8ad6-16d08de92a8e","_cell_guid":"7a4af8c1-736a-430a-8d66-d5a4c0c134f1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"learner = vision_learner(dls, resnet50, metrics=error_rate)","metadata":{"_uuid":"cfdc0259-dc42-4853-8c58-c6b69dd8d62f","_cell_guid":"dcc676ba-1432-4dbc-b8cd-e62e1699074f","trusted":true,"collapsed":false,"id":"c107f724","outputId":"fcc1de68-7c8b-43f5-b9eb-fcdb0773ef07","execution":{"iopub.status.busy":"2025-03-19T00:22:07.165857Z","iopub.execute_input":"2025-03-19T00:22:07.166100Z","iopub.status.idle":"2025-03-19T00:22:07.810606Z","shell.execute_reply.started":"2025-03-19T00:22:07.166070Z","shell.execute_reply":"2025-03-19T00:22:07.809694Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Plot the loss vs learning rate to reduce amount of guesswork on picking a good starting learning rate:","metadata":{"_uuid":"0959f905-6ba3-40b3-b956-ce7edc5d0518","_cell_guid":"06ceeda5-3a0f-4b2c-ad08-43378c7f9143","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":" learner.lr_find()","metadata":{"_uuid":"4a6d9742-d7eb-42cd-8ae0-ba215837a94d","_cell_guid":"232181b6-2d7d-42a8-a1cf-1add44e46880","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:22:07.812154Z","iopub.execute_input":"2025-03-19T00:22:07.812459Z","iopub.status.idle":"2025-03-19T00:22:26.192075Z","shell.execute_reply.started":"2025-03-19T00:22:07.812414Z","shell.execute_reply":"2025-03-19T00:22:26.191283Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Fine tune and show the results ðŸ¥³","metadata":{"_uuid":"ae1e7fc7-1217-409a-9426-06ebf5e66d5c","_cell_guid":"fb45a900-017b-4593-a605-69ed02b491dc","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"learner.fine_tune(200, 10e-3)","metadata":{"_uuid":"1fb1908b-9bd5-4248-974b-623fde11a389","_cell_guid":"83362915-98fd-49df-aa6b-1d4ea7dc0c41","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-03-19T00:22:26.193568Z","iopub.execute_input":"2025-03-19T00:22:26.194332Z","iopub.status.idle":"2025-03-19T00:31:54.443980Z","shell.execute_reply.started":"2025-03-19T00:22:26.194285Z","shell.execute_reply":"2025-03-19T00:31:54.443031Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learner.show_results()","metadata":{"_uuid":"7093573a-cd47-49c8-a426-eb0a62896867","_cell_guid":"1c6b5504-2a1e-481c-9643-c34737b93cb5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T00:31:54.446026Z","iopub.execute_input":"2025-03-19T00:31:54.446811Z","iopub.status.idle":"2025-03-19T00:31:55.171631Z","shell.execute_reply.started":"2025-03-19T00:31:54.446739Z","shell.execute_reply":"2025-03-19T00:31:55.170965Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we can export our trained `Learner`. This contains all the information needed to run the model:","metadata":{"_uuid":"ea9616fb-c51e-4a87-83ac-55c779e79a8f","_cell_guid":"edd767bf-1c2d-43c4-827b-87f74171d476","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"learner.export('cat-meow-vs-dog-bork.pkl')","metadata":{"_uuid":"c6b868b3-44a0-4b44-b910-7c015911708b","_cell_guid":"ab257836-43dc-431d-9385-72b75f7d96e0","trusted":true,"collapsed":false,"id":"ae2bc6ac","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-03-19T00:31:55.172866Z","iopub.execute_input":"2025-03-19T00:31:55.173105Z","iopub.status.idle":"2025-03-19T00:31:55.508530Z","shell.execute_reply.started":"2025-03-19T00:31:55.173076Z","shell.execute_reply":"2025-03-19T00:31:55.507977Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Finally, open the Kaggle sidebar on the right if it's not already, and find the section marked \"Output\". Open the `/kaggle/working` folder, and you'll see `model.pkl`. Click on it, then click on the menu on the right that appears, and choose \"Download\". After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model.","metadata":{"_uuid":"ad2d3011-80f8-4f0e-a46d-a5ae067388d9","_cell_guid":"fdfad666-1045-4081-a2e0-8d330c3970f0","trusted":true,"collapsed":false,"id":"Q2HTrQKTf3BV","jupyter":{"outputs_hidden":false}}}]}